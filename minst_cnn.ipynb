{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\\nTensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\\nTensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\\nTensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\\nTensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\\nTensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final FC 7x7x64 inputs -> 10 outputs\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.345578307\n",
      "Epoch: 0002 cost = 0.091818628\n",
      "Epoch: 0003 cost = 0.068277044\n",
      "Epoch: 0004 cost = 0.056425788\n",
      "Epoch: 0005 cost = 0.046871104\n",
      "Epoch: 0006 cost = 0.041011621\n",
      "Epoch: 0007 cost = 0.036587754\n",
      "Epoch: 0008 cost = 0.032753380\n",
      "Epoch: 0009 cost = 0.027947150\n",
      "Epoch: 0010 cost = 0.025054016\n",
      "Epoch: 0011 cost = 0.022412931\n",
      "Epoch: 0012 cost = 0.020378096\n",
      "Epoch: 0013 cost = 0.017310476\n",
      "Epoch: 0014 cost = 0.015675599\n",
      "Epoch: 0015 cost = 0.013623292\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [9]\n",
      "Prediction:  [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANB/R/22CmgrIUkKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13bf5b68b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
