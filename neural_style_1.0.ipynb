{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural style\n",
    "### This is a simple refactoring of [Anish Athalye's neural style](https://github.com/anishathalye/neural-style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://github.com/sjchoi86/Tensorflow-101/tree/master/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://www.vlfeat.org/matconvnet/models/beta16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np \n",
    "import os \n",
    "import scipy.misc \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "try:\n",
    "    reduce\n",
    "except NameError:\n",
    "    from functools import reduce\n",
    "%matplotlib inline  \n",
    "print (\"Packages loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def net(data_path, input_image):\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    mean = data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0, 1))\n",
    "    weights = data['layers'][0]\n",
    "    net = {}\n",
    "    current = input_image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current)\n",
    "        net[name] = current\n",
    "    assert len(net) == len(layers)\n",
    "    return net, mean_pixel, layers\n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel\n",
    "def imread(path):\n",
    "    return scipy.misc.imread(path).astype(np.float)\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    scipy.misc.imsave(path, img)\n",
    "print (\"Network for VGG ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features of a content image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cwd           = os.getcwd()\n",
    "VGG_PATH      = cwd + \"/data/imagenet-vgg-verydeep-19.mat\"\n",
    "#CONTENT_PATH  = cwd + \"/images/flash.jpg\"\n",
    "CONTENT_PATH  = cwd + \"/images/bundang_square.jpg\"\n",
    "#CONTENT_PATH  = cwd + \"/images/bicycle.jpg\"\n",
    "#CONTENT_PATH  = cwd + \"/images/Opera_House.jpg\"\n",
    "CONTENT_LAYER = 'relu2_2'\n",
    "STYLE_LAYERS  = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')\n",
    "# STYLE_LAYERS  = ('relu1_1', 'relu2_1')\n",
    "\n",
    "raw_content = scipy.misc.imread(CONTENT_PATH)\n",
    "plt.figure(0, figsize=(10, 5))\n",
    "plt.imshow(raw_content)\n",
    "plt.title(\"Original content image\")\n",
    "plt.show()\n",
    "\n",
    "content_image = raw_content.astype(np.float)\n",
    "content_shape = (1,) + content_image.shape # (h, w, nch) =>  (1, h, w, nch) \n",
    "with tf.Graph().as_default(), tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    image = tf.placeholder('float', shape=content_shape)\n",
    "    nets, content_mean_pixel, _ = net(VGG_PATH, image)\n",
    "    content_image_pre = np.array([preprocess(content_image, content_mean_pixel)])\n",
    "    content_features = nets[CONTENT_LAYER].eval(feed_dict={image: content_image_pre})\n",
    "    print (\" Type of 'features' is \", type(content_features))\n",
    "    print (\" Shape of 'features' is %s\" % (content_features.shape,))\n",
    "    # Plot response \n",
    "    for i in range(5):\n",
    "        plt.figure(i, figsize=(10, 5))\n",
    "        plt.matshow(content_features[0, :, :, i], cmap=plt.cm.gray, fignum=i)\n",
    "        plt.title(\"%d-layer content feature\" % (i))\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features of a style image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STYLE_PATH   = cwd + \"/images/style2.jpg\"\n",
    "#STYLE_PATH   = cwd + \"/images/style3.jpg\"\n",
    "raw_style    = scipy.misc.imread(STYLE_PATH)\n",
    "plt.figure(0, figsize=(10, 5))\n",
    "plt.imshow(raw_style)\n",
    "plt.title(\"Original style image\")\n",
    "plt.show()\n",
    "\n",
    "style_image = raw_style.astype(np.float)\n",
    "style_shape = (1,) + style_image.shape # (h, w, nch) =>  (1, h, w, nch) \n",
    "style_features = dict()\n",
    "with tf.Graph().as_default(), tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    image = tf.placeholder('float', shape=style_shape)\n",
    "    nets, _, _ = net(VGG_PATH, image)\n",
    "    style_image_pre = np.array([preprocess(style_image, content_mean_pixel)])\n",
    "    for idx, layer in enumerate(STYLE_LAYERS):\n",
    "        curr_features = nets[layer].eval(feed_dict={image: style_image_pre})\n",
    "        curr_features_vec = np.reshape(curr_features, (-1, curr_features.shape[3]))\n",
    "        gram = np.matmul(curr_features_vec.T, curr_features_vec) / curr_features_vec.size\n",
    "        style_features.update({layer: gram})\n",
    "        # Plot \n",
    "        plt.figure(idx, figsize=(10, 5))\n",
    "        plt.matshow(curr_features[0, :, :, 0], cmap=plt.cm.gray, fignum=idx)\n",
    "        plt.title(\"%d style feature\" % (idx))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "content_weight = 5 # 5 \n",
    "style_weight   = 10 # 10\n",
    "tv_weight      = 100 # 100\n",
    "learning_rate  = 5.\n",
    "iterations     = 500\n",
    "def _tensor_size(tensor):\n",
    "    from operator import mul\n",
    "    return reduce(mul, (d.value for d in tensor.get_shape()), 1)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess, tf.device('/gpu:0'):\n",
    "    initial   = tf.random_normal(content_shape) * 0.256\n",
    "    image2opt = tf.Variable(initial)\n",
    "    nets, mean_pixel, _ = net(VGG_PATH, image2opt)\n",
    "    \n",
    "    # 1. content loss\n",
    "    content_loss = content_weight * (2 * tf.nn.l2_loss(\n",
    "        nets[CONTENT_LAYER] - content_features) / content_features.size)\n",
    "    \n",
    "    # 2. style loss\n",
    "    style_losses = []\n",
    "    for style_layer in STYLE_LAYERS:\n",
    "        layer   = nets[style_layer]\n",
    "        _, height, width, number = layer.get_shape()\n",
    "        size    = height * width * number\n",
    "        feats   = tf.reshape(layer, (-1, number.value))\n",
    "        gram    = tf.matmul(tf.transpose(feats), feats) / size.value\n",
    "        style_gram = style_features[style_layer]\n",
    "        style_losses.append(2 * tf.nn.l2_loss(gram - style_gram) / style_gram.size)\n",
    "    style_loss = style_weight * reduce(tf.add, style_losses)\n",
    "    \n",
    "    # 3. Total variation denoising\n",
    "    tv_y_size = _tensor_size(image2opt[:,1:,:,:])\n",
    "    tv_x_size = _tensor_size(image2opt[:,:,1:,:])\n",
    "    tv_loss = tv_weight * 2 * (\n",
    "        (tf.nn.l2_loss(image2opt[:,1:,:,:] - image2opt[:,:content_shape[1]-1,:,:]) /\n",
    "            tv_y_size) +\n",
    "        (tf.nn.l2_loss(image2opt[:,:,1:,:] - image2opt[:,:,:content_shape[2]-1,:]) /\n",
    "            tv_x_size))\n",
    "    \n",
    "    # Overall loss\n",
    "    loss = content_loss + style_loss + tv_loss\n",
    "    \n",
    "    # optimizer setup\n",
    "    optm = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(iterations):\n",
    "        optm.run()\n",
    "        if i % 100 == 0 or i == iterations-1:\n",
    "            print (\"[%d/%d]\" % (i, iterations))\n",
    "            out = image2opt.eval()\n",
    "            # Plot\n",
    "            stylized_img = out[0, :, :, :] + content_mean_pixel\n",
    "            stylized_img = np.clip(stylized_img, 0, 255).astype('uint8')\n",
    "            plt.figure(0, figsize=(10, 5))\n",
    "            plt.imshow(stylized_img)\n",
    "            plt.title(\"[%d] Stylized image\" % (i))\n",
    "            plt.show()\n",
    "    out = image2opt.eval()\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot final image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(10, 5))\n",
    "plt.imshow(raw_content)\n",
    "plt.title(\"Original content image\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(0, figsize=(10, 5))\n",
    "plt.imshow(raw_style)\n",
    "plt.title(\"Original style image\")\n",
    "plt.show()\n",
    "\n",
    "stylized_img = out[0, :, :, :] + content_mean_pixel\n",
    "stylized_img = np.clip(stylized_img, 0, 255).astype('uint8')\n",
    "plt.figure(1, figsize=(10, 5))\n",
    "plt.imshow(stylized_img)\n",
    "plt.title(\"Stylized image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
