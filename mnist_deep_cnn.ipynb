{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\\nTensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\\nTensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\\nTensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\\nTensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\\nTensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\\nTensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\\nTensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\\nTensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\\nTensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\\nTensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\\nTensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"add_1:0\", shape=(?, 10), dtype=float32)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.360294137\n",
      "Epoch: 0002 cost = 0.096803291\n",
      "Epoch: 0003 cost = 0.072851567\n",
      "Epoch: 0004 cost = 0.059353497\n",
      "Epoch: 0005 cost = 0.051990311\n",
      "Epoch: 0006 cost = 0.044739313\n",
      "Epoch: 0007 cost = 0.042151516\n",
      "Epoch: 0008 cost = 0.040640227\n",
      "Epoch: 0009 cost = 0.035355603\n",
      "Epoch: 0010 cost = 0.033902762\n",
      "Epoch: 0011 cost = 0.030063476\n",
      "Epoch: 0012 cost = 0.029985783\n",
      "Epoch: 0013 cost = 0.026657204\n",
      "Epoch: 0014 cost = 0.027299417\n",
      "Epoch: 0015 cost = 0.025901888\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9941\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [0]\n",
      "Prediction:  [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b7bc066c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
